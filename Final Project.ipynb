{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import json\n",
    "import requests\n",
    "import requests_cache\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import urlparse\n",
    "import csv\n",
    "import urllib\n",
    "import os\n",
    "import os.path\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "from lxml import html\n",
    "import lxml.html as lx\n",
    "\n",
    "requests_cache.install_cache('demo_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Popular_Movies_search(year,pages,num):\n",
    "    count = 0\n",
    "    names = []\n",
    "    \n",
    "    for i in range(1,(pages+1)):\n",
    "        url = \"http://www.imdb.com/search/title?sort=moviemeter,asc&title_type=feature&year=\" + str(year) + \",\" +str(year) + \"&\" + \"page=\" + str(i) + \"&\" + \"ref_=adv_prv\"        \n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "        search_results = soup.find_all(\"p\", class_=\"sort-num_votes-visible\")\n",
    "        vote = int(search_results[0].find_all('span')[1].text.replace(',',''))\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "        search_results = soup.find_all(\"div\", class_=\"lister-item-content\")\n",
    "        \n",
    "\n",
    "        for result in search_results:\n",
    "            try:\n",
    "                vote = int(result.find_all('p')[3].find_all('span')[1].text.replace(',',''))\n",
    "                if vote < 10000:\n",
    "                    continue\n",
    "            except:\n",
    "                continue\n",
    "            header = result.find(\"h3\", class_=\"lister-item-header\")\n",
    "            title = header.a\n",
    "            b = title.get_text().encode('utf-8')\n",
    "            names.append(b)\n",
    "            count = count + 1\n",
    "            if count == num:\n",
    "                return names\n",
    "            \n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Movie_info_search(term):\n",
    "    url = 'http://www.omdbapi.com/?t='+term.replace(' ','+')+'&plot=full&tomatoes=true'\n",
    "    response = requests.get(url)\n",
    "    try:\n",
    "        js = response.json()\n",
    "        map(js.pop, ['Plot','DVD','tomatoFresh','tomatoConsensus','tomatoMeter','tomatoRating','tomatoRotten','tomatoURL','tomatoUserMeter','tomatoUserRating','tomatoUserReviews','tomatoReviews'])\n",
    "    except:\n",
    "        return {}\n",
    "    meta_url = 'http://www.metacritic.com/movie/'+term.replace(' ','-')\n",
    "    return js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Scoring_search(movie):\n",
    "    imdb = Movie_info_search(movie).values()[-4]\n",
    "    url = 'http://www.imdb.com/title/' + str(imdb) + '/ratings?ref_=tt_ov_rt'\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    res_2 = soup.find_all('td')\n",
    "    \n",
    "    rates = []\n",
    "    try:\n",
    "        for i in xrange(14):\n",
    "            number = str(res_2[37 + 3*i].text.replace(u'\\xa0',u''))\n",
    "            rate = str(res_2[38 + 3*i].find_all('img')[0].text.replace(u'\\xa0',u''))\n",
    "            rates.append([number + ',' + rate])\n",
    "    except:\n",
    "        print 'sdfdsf'\n",
    "    \n",
    "    params = {'males':rates[0], 'females':rates[1],'<18':rates[2], 'males<18':rates[3],'females<18':rates[4], '18-29':rates[5],'males 18-29':rates[6], 'females 18-29':rates[7],'30-44':rates[8],'males 30-44':rates[9], 'females 30-44':rates[10], '45+':rates[11],'males 45+':rates[12], 'females 45+':rates[13]}\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'18-29': ['77781,8.6'],\n",
       " '30-44': ['42045,8.1'],\n",
       " '45+': ['10303,7.8'],\n",
       " '<18': ['2086,9.2'],\n",
       " 'females': ['38798,8.3'],\n",
       " 'females 18-29': ['22798,8.5'],\n",
       " 'females 30-44': ['9377,8.1'],\n",
       " 'females 45+': ['2244,7.7'],\n",
       " 'females<18': ['651,9.0'],\n",
       " 'males': ['104358,8.4'],\n",
       " 'males 18-29': ['54069,8.7'],\n",
       " 'males 30-44': ['31978,8.1'],\n",
       " 'males 45+': ['7867,7.8'],\n",
       " 'males<18': ['1409,9.2']}"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scoring_search('la la land')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Comment_search(movie,gender):\n",
    "    comments = []\n",
    "    imdb = imdb = Movie_info_search(movie).values()[-1]\n",
    "    url = 'http://www.imdb.com/title/'+str(imdb)+'/reviews?filter=custom&spoiler=&vote_min=&vote_max=&gender='+gender+'&age_min=&age_max=&country=&order=score&custom=1'\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    div = soup.find('div', attrs = {'id' : 'tn15content'}).find_all('p')\n",
    "    for contents in div:\n",
    "        \n",
    "        comments.append(contents.text.replace('\\n',' '))\n",
    "    \n",
    "    return comments\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "films_name = []\n",
    "films_data = pd.DataFrame()\n",
    "for year in xrange(0,15):\n",
    "    films_name.append(Popular_Movies_search(year+2002,10,100))\n",
    "    films_data = pd.concat([films_data,pd.DataFrame.from_dict(Movie_info_search(i) for i in films_name[year])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "films_data.reset_index(drop = True)\n",
    "films_data.to_csv('Films_data.csv',encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
